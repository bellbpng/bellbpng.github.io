---
layout: single
title:  "Deep Learning from Scratch1 - Ch7 합성곱 신경망(CNN)"
excerpt: "합성곱 계층, 풀링 계층"

categories:
  - Deep Learning from Scratch1
# tags:
#   - [ML, Python]

toc: true
toc_sticky: true
---

# 합성곱 신경망(CNN)

- 이미지 인식과 음성 인식 등 다양한 곳에서 사용되며 특히, 이미지 인식 분야에서 딥러닝을 활용한 대부분의 기법에서 CNN을 기초로 한다.

## 합성곱 계층(Convolutional layer)

- 완전연결 계층(Affine 계층)과는 다르게 합성곱 계층은 형상을 유지한다. 이미지도 3차원 데이터(세로, 가로, 채널(색상))로 입력받으며 다음 계층에도 3차원 데이터로 전달한다. 
- 따라서 CNN 에서는 이미지 같이 형상을 가진 데이터를 제대로 이해할 가능성이 있다.
- 합성곱 계층의 입출력 데이터를 특징 맵(feature map) 이라고도 한다.

### 합성곱 연산

- 이미지 처리에서 말하는 필터(커널) 연산이다.
- 입력 데이터와 필터 모두 형상을 가지고 있고 필터의 윈도우(window - 음영처리된 부분)를 일정 간격으로 이동해가며 입력 데이터에 적용한다. 
- 입력과 필터에서 대응하는 원소끼리 곱한 후 그 총합을 구한다. (단일 곱셈-누산, fused multiply-add,, FMA)
- CNN에서는 필터의 매개변수가 '가중치'에 해당하고 편향도 존재한다. 편향은 필터를 적용 한 후의 데이터에 더해지고 항상 하나만(1x1)만 존재한다.

<img src="https://user-images.githubusercontent.com/59792046/153416195-2f12190e-eeff-4892-a33c-cc0f6906d6d5.png" width="700">

<img  src="https://user-images.githubusercontent.com/59792046/153416390-dba40079-dd31-4fc9-ac20-167b3e896caf.png" width="700">

### 패딩(Padding)

- 합성곱 연산을 수행하기 전에 입력 데이터 주변을 특정 값으로 채우는 방법
- 출력 크기를 조정할 목적으로 사용한다. 패딩을 키우면 출력 크기가 커진다.
- 합성곱 연산을 거칠 때마다 크기가 작아지면 어느 시점에서는 출력 크기가 1이 되어버려서 더 이상 합성곱 연산을 적용할 수 없어진다. 따라서 이를 막기 위해 패딩을 사용한다.

### 스트라이드(Stride)

- 필터를 적용하는 위치의 간격을 말한다.
- 스트라이드를 어떻게 설정하는지에 따라 윈도우의 이동 정도가 결정된다. 예를 들어, 2로 설정하면 윈도우는 두 칸씩 이동한다.
- 스트라이드를 키우면 출력 크기는 작아진다. 

#### 패딩, 스트라이드, 출력 크기의 관계

- 입력 크기를 (H,W), 필터 크기를 (FH, FW), 출력 크기를 (OH, OW), 패딩을 P, 스트라이드를 S 라 하자
- OH = (H+2P-FH)/S + 1, OW = (W+2P-FW)/S + 1

### 3차원 데이터의 합성곱 연산
- 이미지는 세로,가로,채널까지 고려하는 3차원 데이터이다.
- 채널쪽으로 특징맵이 여러 개 있다면 입력 데이터와 필터의 합성곱 연산을 채널마다 수행하고, 그 결과를 더해서 하나의 출력을 얻는다.
- 입력 데이터의 채널 수와 필터의 채널 수가 같아야 한다.
- 채널이 1개인 출력 특징 맵이 아니라 다수의 채널을 가진 출력을 내보내려면 필터(가중치)를 다수 이용하면 된다.
- 따라서 필터의 가중치 데이터는 4차원 데이터로 (출력 채널 수(FN), 입력 채널 수(C), 높이(FH), 너비(FW)) 순으로 쓴다.
- 각 계층을 흐르는 데이터의 차원을 하나 늘려 4차원 데이터로 저장하면 배치처리를 지원할 수 있다. 데이터를 (데이터의 수(N), 채널 수(C), 높이(H), 너비(W)) 순으로 저장한다.


<img src="https://user-images.githubusercontent.com/59792046/153419233-add6f1f9-6399-4abf-9905-820e61bbd53b.png" width="700">

<img src="https://user-images.githubusercontent.com/59792046/153419926-02292288-dad3-4af6-973b-ca158b617ebc.png" width="700">

## 풀링 계층(Pooling layer)

- 세로,가로 방향의 공간을 줄이는 연산이다.
- 풀링의 윈도우 크기와 스트라이드는 같은 값으로 설정하는 것이 보통이다.
- 최대풀링(max pooling)은 윈도우에서 가장 큰 원소 하나를 꺼내는 것으로 이미지 인식 분야에서 주로 사용된다.
- 평균풀링(average pooling)은 윈도우 영역에서 평균을 계산한다.

<img src="https://user-images.githubusercontent.com/59792046/153420879-054d72d0-b0eb-45fe-a131-6fc4a3087ee8.png" width="700">

### 풀링 계층의 특징
- 대상 영역에서 최댓값이나 평균을 계산하는 명확한 처리이므로 특별히 학습할 매개변수가 없다.
- 채널마다 독립적으로 계산하기 때문에 입력 데이터의 채널 수 그대로 출력 데이터로 내보낸다.
- 입력의 변화에 영향을 적게 받는다.


#### 참고자료
- 밑바닥부터 시작하는 딥러닝