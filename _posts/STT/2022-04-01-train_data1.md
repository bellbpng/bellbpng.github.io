---
layout: single
title:  "데이터 준비하기1"
excerpt: "traing data pre-processing"

categories:
  - SpeechToText
# tags:
#   - [ML, Python]

toc: true
toc_sticky: true
---

전달받은 음성파일은 총 3000개. 

이번 프로젝트의 최종 목표는 얼마나 깨끗하게 음성파일에서 speech 만을 분리해내어, STT 성능을 높이는 것이다.

하지만, 예능, 스포츠, 뉴스 등과 같이 생활 미디어를 가지고 speech 만을 뽑아내는 연구는 많이 진행되지 않았어서 참고할 수 있는 데이터가 많이 없는게 아쉬운 점이다.

일단 전달받은 데이터를 가지고 정답데이터(teacher data)를 만들어야 한다. 훈련모델로는 vocal-remover 오픈소스를 활용할 것이다. -> [Vocal Remover](https://github.com/tsurumeso/vocal-remover)

정답 데이터를 만들어가는 과정 중 첫번째는, vocal-remover의 성능이 악기소리 제거에는 정말 효율적이다. 따라서 1차적으로 original 파일을 vocal-remover 를 활용해서 vocals, instruments 파일로 분리한다. 

그 다음으로 각 original 파일에 대한 vocals, instruments의 파형을 시간대에서 관찰한다. 그리고 vocals 이 돋보이면서 instruments는 최소화 된 부분을 찾아서 파싱하여 새롭게 추출한다. 그리고 이 음성파일들이 정답데이터(teacher)가 된다. 

정답데이터를 다 만들면 정답데이터에 사람 발화 주파수에 비슷한 대역의 노이즈를 입혀서 훈련데이터로 만들어 볼 생각이다. 이는 진행하면서 또 포스팅을 이어서 해야겠다.


이번 포스팅은 아나콘다 가상환경에서 배치파일로 plot 추출하는 것까지만 포스팅을 진행한다.

아마 추후에 포스팅을 진행하면서 코드는 조금씩 수정이 이루어지겠지만, 개인 기록용으로 남겨둘 예정이다. 워낙 배우는게 많아서....


## 음성파일 시간에 따른 파형을 이미지 파일로 변환하여 저장하기


```python

import argparse
import librosa
import librosa.display
import matplotlib.pyplot as plt
import numpy as np
import wave
from pydub import AudioSegment

class Signal_extractor(object):

    def __init__(self):
        pass

    def make_plot(title, signal, sr, output_plot):
        
        plt.figure(figsize=(24,4));
        plt.title(title + " Signal Wave...");
        plt.xlabel('Time');
        plt.ylabel('Amplitude');
        librosa.display.waveplot(signal, sr)
        plt.savefig(output_plot);


    def Audio_PostProcessor(path, file_name,):
        input_V = path + "\\" + file_name + "_Vocals_mono.wav"
        input_I = path + "\\" + file_name + "_Instruments_mono.wav"

        #Voice Process
        print(input_V, ":Vocals post-processing started")
        signal_V, sr_v = librosa.load(input_V) # wave 파일 읽어오기

        #Instrument Process
        print(input_I, ":Instruments post-processing started")
        signal_I, sr_i = librosa.load(input_I) # wave 파일 읽어오기

        #Extract each signal plot
        output_plot= path+"\\signal_plots\\"+file_name+"_Vocals.png"
        Signal_extractor.make_plot("Vocals", signal_V, sr_v, output_plot)

        output_plot= path+"\\signal_plots\\"+file_name+"_Instruments.png"
        Signal_extractor.make_plot("Instruments", signal_I, sr_i, output_plot)


def main():
    p = argparse.ArgumentParser()
    p.add_argument('--path', '-P', type=str, default='.')
    p.add_argument('--input', '-i', required=True)

    args = p.parse_args()
    path = args.path
    file_name = args.input


    Signal_extractor.Audio_PostProcessor(path, file_name)

if __name__ == '__main__':
    main()


```


## 가상환경에서 동작하는 배치파일 만들기

[참고한 블로그](https://jangjy.tistory.com/362)


```txt

set root=C:\Anaconda3
call %root%\Scripts\activate.bat %root%

call conda env list
call conda activate image
call cd E:\STT_Accuracy_PreProcessor

for /L %%i in (0,1,9) do ( call python Signal_extractor.py --path E:\SBS_contents\Vocal_Remover_out_mono -input SBS_C000%%i )
#for /L %%i in (10,1,99) do ( call python Signal_extractor.py --path E:\SBS_contents\Vocal_Remover_out_mono -input SBS_C00%%i )
#for /L %%i in (100,1,999) do ( call python Signal_extractor.py --path E:\SBS_contents\Vocal_Remover_out_mono -input SBS_C0%%i )
#for /L %%i in (1000,1,2998) do ( call python Signal_extractor.py --path E:\SBS_contents\Vocal_Remover_out_mono -input SBS_C%%i )

```

- 위 파일을 메모장으로 작성하고, 다른 이름으로 저장 -> 확장자명 .bat
- 아나콘다 가상환경에서 배치파일을 돌리는 방법이다. 알아두면 유용하고 편하다.


